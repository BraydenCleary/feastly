{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use SpaCy\n",
    "\n",
    "### Contents:\n",
    "\n",
    "* [Installing SpaCy](#SpaCy-install)\n",
    "* [Using the parser](#Using-the-Parser)\n",
    "* [Using the tokens from the parser](#Some-basic-usage-on-tokens)\n",
    "* [Getting noun chunks and entities](#Noun-Chunks-and-Entities)\n",
    "* [Getting logical dependency](#Logical-Dependency)\n",
    "* [Parallelization](#Local-Parallelization)\n",
    "* [Extra thing possible with the loaded dictionary](#Finding-other-similar-words)\n",
    "* [Issues](#Issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy install\n",
    "` \n",
    "pip install -U spacy\n",
    "python -m spacy download en\n",
    "`\n",
    "\n",
    "Spacy comes with a dictionary, and there's this much more comprehensive one:\n",
    "\n",
    "`\n",
    "python -m spacy download en_core_web_md\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \\\n",
    "u'''Dr. Howard's dog, Ubuntu, jumped out the window.\n",
    "I took a shot of whiskey; it tasted nothing like Angel's Envy from yesterday.\n",
    "It smelled of unripe bananas, blood oranges and tart, but no lactic sourness.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the more comprehensive Spacy directly as a parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name util",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f18394e2e43b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# parser = spacy.load('en_core_web_md')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/braydencleary/anaconda2/lib/python2.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresolve_model_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name util"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# parser = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using numpy for cosine similarity to compare later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cosine = lambda v1, v2: dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "cos_similarity = lambda w1, w2: cosine(w1.vector, w2.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Parser\n",
    "Running 'parser' tokenizes a single document\n",
    "(A document must be unicode!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Howard's dog, Ubuntu, jumped out the window.\n",
      "I took a shot of whiskey; it tasted nothing like Angel's Envy from yesterday.\n",
      "It smelled of unripe bananas, blood oranges and tart, but no lactic sourness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document = parser(s)\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Howard's dog, Ubuntu, jumped out the window.\n",
      "\n",
      "I took a shot of whiskey; it tasted nothing like Angel's Envy from yesterday.\n",
      "\n",
      "It smelled of unripe bananas, blood oranges and tart, but no lactic sourness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in document.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic usage on tokens\n",
    "Going through the tokens in the document, printing the lemma, word class, its similarity to \"Apples\" (for fun), and the sum of its word vector (to check it exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word        Lemma       Class       Builtin     Cosine      Vector    \n",
      "Howard      howard      PROPN       0.09012     0.09012    -4.7779\n",
      "dog         dog         NOUN        0.20634     0.20634     2.9046\n",
      "Ubuntu      ubuntu      PROPN       0.05689     0.05689   -13.1991\n",
      "jumped      jump        VERB        0.16759     0.16759    -5.1246\n",
      "out         out         ADP         0.28142     0.28142     4.5354\n",
      "the         the         DET         0.18507     0.18507    -1.2607\n",
      "window      window      NOUN        0.14864     0.14864     4.4842\n",
      "I           -PRON-      PRON        0.20443     0.20443    -7.8471\n",
      "took        take        VERB        0.18219     0.18219     2.5328\n",
      "a           a           DET         0.12858     0.12858     0.0272\n",
      "shot        shot        NOUN        0.12384     0.12384    -0.6114\n",
      "of          of          ADP         0.17137     0.17137     1.1305\n",
      "whiskey     whiskey     NOUN        0.34929     0.34929   -12.0690\n",
      "it          -PRON-      PRON        0.29234     0.29234    -2.0743\n",
      "tasted      taste       VERB        0.46929     0.46929    -1.4315\n",
      "nothing     nothing     NOUN        0.29555     0.29555     1.1957\n",
      "like        like        ADP         0.32987     0.32987    -0.1397\n",
      "Angel       angel       PROPN       0.20576     0.20576   -12.3159\n",
      "Envy        envy        PROPN       0.21317     0.21317    -5.8443\n",
      "from        from        ADP         0.17041     0.17041     8.7295\n",
      "yesterday   yesterday   NOUN        0.18989     0.18989    -3.0692\n",
      "It          -PRON-      PRON        0.29234     0.29234    -2.0743\n",
      "smelled     smell       VERB        0.33258     0.33258    -5.8586\n",
      "of          of          ADP         0.17137     0.17137     1.1305\n",
      "unripe      unripe      ADJ         0.49297     0.49297   -14.0533\n",
      "bananas     banana      NOUN        0.75027     0.75027    -6.6682\n",
      "blood       blood       NOUN        0.19683     0.19683    -2.6618\n",
      "oranges     orange      NOUN        0.77809     0.77809    -2.3007\n",
      "and         and         CCONJ       0.24098     0.24098     1.4990\n",
      "tart        tart        NOUN        0.60639     0.60639    -6.9629\n",
      "but         but         CCONJ       0.27892     0.27892    -1.6428\n",
      "no          no          DET         0.17563     0.17563     4.4184\n",
      "lactic      lactic      ADJ         0.22370     0.22370     0.2889\n",
      "sourness    sourness    NOUN        0.32529     0.32529   -15.5927\n"
     ]
    }
   ],
   "source": [
    "apples = parser(u'apples')\n",
    "\n",
    "print(\"{:10}  {:10}  {:10}  {:10}  {:10}  {:10}\".format(\"Word\", \"Lemma\", \"Class\", \"Builtin\", \"Cosine\", \"Vector\"))\n",
    "for token in document: \n",
    "    if token.is_alpha : print(\"{:10}  {:10}  {:10}  {:.5f}  {:10.5f} {:10.4f}\".format(token,\n",
    "                                                                                      token.lemma_,\n",
    "                                                                                      token.pos_,\n",
    "                                                                                      token.similarity(apples),\n",
    "                                                                                      cos_similarity(apples,token),\n",
    "                                                                                      sum(token.vector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy claims oranges are closer to apples than bananas.\n",
    "\n",
    "## Noun Chunks and Entities\n",
    "\n",
    "Amazingly spacy can directly extract noun chunks and entities. I'm not sure how entities might be useful though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Chunk            Lemmatized Chunk      Similarity to Red Apples\n",
      "Dr. Howard's dog      dr. howard 's dog     0.31278\n",
      "the window            the window            0.35839\n",
      "I                     -PRON-                0.31608\n",
      "a shot                a shot                0.32617\n",
      "whiskey               whiskey               0.38732\n",
      "it                    -PRON-                0.38155\n",
      "nothing               nothing               0.37697\n",
      "Angel's Envy          angel 's envy         0.38522\n",
      "yesterday             yesterday             0.23516\n",
      "It                    -PRON-                0.38155\n",
      "unripe bananas        unripe banana         0.62457\n",
      "blood oranges         blood orange          0.69092\n",
      "tart                  tart                  0.57832\n",
      "no lactic sourness    no lactic sourness    0.37129\n"
     ]
    }
   ],
   "source": [
    "red_apples = parser(u'Red Apples')\n",
    "\n",
    "print(\"{:20}  {:20}  {:20}\".format(\"Noun Chunk\", \"Lemmatized Chunk\", \"Similarity to Red Apples\"))\n",
    "for chunk in document.noun_chunks: \n",
    "    print(\"{:20}  {:20}  {:.5f}\".format(chunk, chunk.lemma_, chunk.similarity(red_apples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Howard, Angel, yesterday)\n"
     ]
    }
   ],
   "source": [
    "print(document.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical Dependency\n",
    "Spacy can also find out how words are linked in a document. Could be useful for making features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship    Word            Target          Left dependencies         Right dependencies      \n",
      "poss            Howard          dog             [u'Dr.']                  [u\"'s\"]                 \n",
      "nsubj           dog             jumped          [u'Howard']               [u',', u'Ubuntu', u','] \n",
      "appos           Ubuntu          dog             []                        []                      \n",
      "ROOT            jumped          jumped          [u'dog']                  [u'out', u'.']          \n",
      "prep            out             jumped          []                        [u'window']             \n",
      "det             the             window          []                        []                      \n",
      "pobj            window          out             [u'the']                  []                      \n",
      "nsubj           I               took            []                        []                      \n",
      "ccomp           took            tasted          [u'I']                    [u'shot']               \n",
      "det             a               shot            []                        []                      \n",
      "dobj            shot            took            [u'a']                    [u'of']                 \n",
      "prep            of              shot            []                        [u'whiskey']            \n",
      "pobj            whiskey         of              []                        []                      \n",
      "nsubj           it              tasted          []                        []                      \n",
      "ROOT            tasted          tasted          [u'took', u';', u'it']    [u'nothing', u'.']      \n",
      "dobj            nothing         tasted          []                        [u'like']               \n",
      "prep            like            nothing         []                        [u'Envy']               \n",
      "poss            Angel           Envy            []                        [u\"'s\"]                 \n",
      "pobj            Envy            like            [u'Angel']                [u'from']               \n",
      "prep            from            Envy            []                        [u'yesterday']          \n",
      "pobj            yesterday       from            []                        []                      \n",
      "nsubj           It              smelled         []                        []                      \n",
      "ROOT            smelled         smelled         [u'It']                   [u'of', u',', u'but', u'sourness', u'.']\n",
      "prep            of              smelled         []                        [u'bananas']            \n",
      "amod            unripe          bananas         []                        []                      \n",
      "pobj            bananas         of              [u'unripe']               [u',', u'oranges']      \n",
      "compound        blood           oranges         []                        []                      \n",
      "conj            oranges         bananas         [u'blood']                [u'and', u'tart']       \n",
      "cc              and             oranges         []                        []                      \n",
      "conj            tart            oranges         []                        []                      \n",
      "cc              but             smelled         []                        []                      \n",
      "det             no              sourness        []                        []                      \n",
      "compound        lactic          sourness        []                        []                      \n",
      "conj            sourness        smelled         [u'no', u'lactic']        []                      \n"
     ]
    }
   ],
   "source": [
    "print(\"{:14}  {:14}  {:14}  {:24}  {:24}\".format(\"Relationship\", \"Word\", \"Target\", \"Left dependencies\", \"Right dependencies\"))\n",
    "for token in document:\n",
    "    if token.is_alpha : print(\"{:14}  {:14}  {:14}  {:24}  {:24}\".format(token.dep_, token.orth_, token.head.orth_,\n",
    "                                                                         [t.orth_ for t in token.lefts],\n",
    "                                                                         [t.orth_ for t in token.rights]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Parallelization\n",
    "Spacy can parallelize across threads. I have no idea if it can automatically parallelize across machines, but that might just be asking for too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def s_again_generator(n):\n",
    "    \"generate n documents about Dr. Howard's Dog\"\n",
    "    for i in range(n):\n",
    "        yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelized Time\n",
      "CPU times: user 2.54 s, sys: 49.7 ms, total: 2.59 s\n",
      "Wall time: 2.73 s\n",
      "\n",
      "Unparallelized Time\n",
      "CPU times: user 2.99 s, sys: 55.2 ms, total: 3.04 s\n",
      "Wall time: 3.15 s\n"
     ]
    }
   ],
   "source": [
    "def time_pipe(n):\n",
    "    for doc in parser.pipe(s_again_generator(n), batch_size=50, n_threads=4):\n",
    "        pass\n",
    "\n",
    "def time_naive(n):\n",
    "    for doc in s_again_generator(n):\n",
    "        parser(doc)\n",
    "\n",
    "print(\"Parallelized Time\")\n",
    "% time time_pipe(500)\n",
    "\n",
    "print(\"\\nUnparallelized Time\")\n",
    "% time time_naive(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding other similar words\n",
    "Since a whole dictionary is loaded into spacy, it can find words similar to a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of SpaCy's dictionary: 247539\n"
     ]
    }
   ],
   "source": [
    "whiskey = parser(u'whiskey')\n",
    "is_actually_a_word = lambda word: word.has_vector and word.is_alpha and word.is_lower and word.lower_\n",
    "\n",
    "spacy_dictionary = filter(is_actually_a_word, parser.vocab)\n",
    "spacy_dictionary.sort(key=lambda word: word.similarity(whiskey))\n",
    "spacy_dictionary.reverse()\n",
    "\n",
    "print(\"Size of SpaCy's dictionary: {}\".format(len(spacy_dictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 most similar words to whiskey:\n",
      "whiskey          liquor           bottle           sherry           ale            \n",
      "whisky           booze            whiskies         bitters          syrup          \n",
      "bourbon          moonshine        beers            rye              alcoholic      \n",
      "scotch           malt             liquors          brew             distilled      \n",
      "gin              distillery       liqueur          cask             cocktails      \n",
      "rum              whiskeys         drank            drinking         bottles        \n",
      "vodka            cognac           martini          bottled          lager          \n",
      "brandy           drink            coke             wine             molasses       \n",
      "tequila          cider            pint             drinks           vermouth       \n",
      "beer             wiskey           distilleries     schnapps         soda           \n"
     ]
    }
   ],
   "source": [
    "spd = spacy_dictionary\n",
    "\n",
    "print(\"Top 50 most similar words to whiskey:\")\n",
    "for w1, w2, w3, w4, w5 in zip(spd[:10], spd[10:20], spd[20:30], spd[30:40], spd[40:50]):   \n",
    "    print(\"{:15}  {:15}  {:15}  {:15}  {:15}\".format(w1.orth_, w2.orth_, w3.orth_, w4.orth_, w5.orth_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues\n",
    "* #### I can't get sentiments to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal sentiment word <whiskey> has a sentiment of 0.0.\n"
     ]
    }
   ],
   "source": [
    "spacy_dictionary.sort(key=lambda word: word.sentiment)\n",
    "print(\"Maximal sentiment word <{}> has a sentiment of {}.\".format(spacy_dictionary[0].orth_, spacy_dictionary[0].sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### The way I treat parser(u'whiskey') like a token was deceptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: whiskey, token: whiskey\n"
     ]
    }
   ],
   "source": [
    "whiskey = parser(u'whiskey')\n",
    "whiskey_token = list(whiskey)[0]\n",
    "print(\"document: {}, token: {}\".format(whiskey, whiskey_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'spacy.tokens.doc.Doc'>\n",
      "<type 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(type(whiskey))\n",
    "print(type(whiskey_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whiskey-whiskey similarity: 1.00000000298\n"
     ]
    }
   ],
   "source": [
    "print(\"whiskey-whiskey similarity: {}\".format(whiskey.similarity(whiskey_token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Don't know how to get the similarity function to use lemmas (I don't plan to use it though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: distillery distillery\n",
      "cosine: 0.813246243064\n",
      "\n",
      "token type: <type 'spacy.tokens.token.Token'>, lemma type: <type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "distil_doc = list(parser(u'distillery distilleries'))\n",
    "print(\"lemmas: {} {}\".format(distil_doc[0].lemma_, distil_doc[1].lemma_))\n",
    "print(\"cosine: {}\\n\".format(distil_doc[0].similarity(distil_doc[1])))\n",
    "\n",
    "print(\"token type: {}, lemma type: {}\".format(type(distil_doc[0]),type(distil_doc[0].lemma_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
