{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as scs\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickets = pd.read_csv('./tickets.csv', delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meal_price_outliers = list(tickets[(tickets.ticket_price < 5) | (tickets.ticket_price > 200)].meal_id)\n",
    "\n",
    "def is_meal_with_crazy_ticket_price(row):\n",
    "    if row['meal_id'] in meal_price_outliers:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "tickets = tickets[tickets.apply(is_meal_with_crazy_ticket_price, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tickets[['percentage_of_seats_sold', 'meal_id','number_of_seats', 'ticket_price', 'sold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meals = pd.read_csv('./cleaned/meals.csv', header=None, names=['Id',\n",
    " 'Cook Id', 'Venue Id', 'Menu Id', 'Is Cancelled', 'Is Active', 'Title', 'Meal Date', 'Day of Date Added', 'Is Public?', 'Number Of Seats', 'Venue Style', 'Venue Capacity', 'Area Id', 'Menu Style', 'Cuisine Type', 'Meal Categories', 'is_category_kosher', 'is_category_paleo', 'is_category_organic', 'is_category_vegetarian', 'is_category_vegan', 'is_category_gluten_free', 'is_category_raw', 'is_category_halal', 'is_category_local', 'is_cuisine_type_portuguese', 'is_cuisine_type_irish', 'is_cuisine_type_cajun_creole', 'is_cuisine_type_polynesian', 'is_cuisine_type_chinese', 'is_cuisine_type_peruvian', 'is_cuisine_type_chamorro', 'is_cuisine_type_belgian', 'is_cuisine_type_central_american', 'is_cuisine_type_mediterranean', 'is_cuisine_type_japanese', 'is_cuisine_type_mexican', 'is_cuisine_type_singaporean', 'is_cuisine_type_ecuadorian', 'is_cuisine_type_persian', 'is_cuisine_type_lao', 'is_cuisine_type_asian', 'is_cuisine_type_latin_american', 'is_cuisine_type_spanish', 'is_cuisine_type_ice_cream_gelato', 'is_cuisine_type_barbecue', 'is_cuisine_type_cafe', 'is_cuisine_type_thai', 'is_cuisine_type_paleo', 'is_cuisine_type_caribbean', 'is_cuisine_type_health_food', 'is_cuisine_type_argentinian', 'is_cuisine_type_hispanic', 'is_cuisine_type_tapas_small_plates', 'is_cuisine_type_european', 'is_cuisine_type_desserts_bakeries', 'is_cuisine_type_south_american', 'is_cuisine_type_gastropub_food', 'is_cuisine_type_other', 'is_cuisine_type_guatemalan', 'is_cuisine_type_brazilian', 'is_cuisine_type_korean', 'is_cuisine_type_salvadorian', 'is_cuisine_type_pizza', 'is_cuisine_type_indonesian', 'is_cuisine_type_balkan', 'is_cuisine_type_srilankan', 'is_cuisine_type_indian', 'is_cuisine_type_hawaiian', 'is_cuisine_type_jewish', 'is_cuisine_type_taiwanese', 'is_cuisine_type_african', 'is_cuisine_type_middle_eastern', 'is_cuisine_type_french', 'is_cuisine_type_asian_noodle_soup', 'is_cuisine_type_vegan', 'is_cuisine_type_german', 'is_cuisine_type_russian', 'is_cuisine_type_vietnamese', 'is_cuisine_type_brunch', 'is_cuisine_type_australian', 'is_cuisine_type_cuban', 'is_cuisine_type_filipino', 'is_cuisine_type_vegetarian', 'is_cuisine_type_turkish', 'is_cuisine_type_malaysian', 'is_cuisine_type_british', 'is_cuisine_type_colombian', 'is_cuisine_type_north_african', 'is_cuisine_type_greek', 'is_cuisine_type_burmese', 'is_cuisine_type_east_european', 'is_cuisine_type_nordic', 'is_cuisine_type_north_american', 'is_cuisine_type_american', 'is_cuisine_type_italian', 'is_cuisine_type_seafood', 'is_cuisine_type_soul_food', 'is_cuisine_type_californian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meals['meal_date'] = pd.to_datetime(meals['Meal Date'])\n",
    "meals['created_date'] = pd.to_datetime(meals['Day of Date Added'])\n",
    "meals['meal_year'] = meals['meal_date'].apply(lambda x: x.year)\n",
    "meals['meal_month'] = meals['meal_date'].apply(lambda x: x.month)\n",
    "meals['meal_day_of_week'] = meals['meal_date'].apply(lambda x: x.weekday())\n",
    "meals['meal_is_on_weekday'] = meals['meal_day_of_week'].apply(lambda x: 1 if x < 5 else 0)\n",
    "meals['listed_days'] = (meals['meal_date'] - meals['created_date']).apply(lambda x: x.days if x.days > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meals = meals[['Id', 'Venue Id', 'Menu Id', 'meal_date', 'meal_is_on_weekday', 'listed_days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "menus = pd.read_csv('./cleaned/menus.csv', header=None, names=['Id', 'Cook Id', 'Title', 'About', 'Cuisine Type', 'Day of Date Added', 'Menu Style', 'Count of distinct Menu Dish Id', 'is_menus_cuisine_type_portuguese', 'is_menus_cuisine_type_irish', 'is_menus_cuisine_type_cajun_creole', 'is_menus_cuisine_type_polynesian', 'is_menus_cuisine_type_chinese', 'is_menus_cuisine_type_peruvian', 'is_menus_cuisine_type_chamorro', 'is_menus_cuisine_type_belgian', 'is_menus_cuisine_type_central_american', 'is_menus_cuisine_type_mediterranean', 'is_menus_cuisine_type_japanese', 'is_menus_cuisine_type_mexican', 'is_menus_cuisine_type_singaporean', 'is_menus_cuisine_type_ecuadorian', 'is_menus_cuisine_type_persian', 'is_menus_cuisine_type_lao', 'is_menus_cuisine_type_asian', 'is_menus_cuisine_type_latin_american', 'is_menus_cuisine_type_spanish', 'is_menus_cuisine_type_ice_cream_gelato', 'is_menus_cuisine_type_barbecue', 'is_menus_cuisine_type_cafe', 'is_menus_cuisine_type_thai', 'is_menus_cuisine_type_paleo', 'is_menus_cuisine_type_caribbean', 'is_menus_cuisine_type_health_food', 'is_menus_cuisine_type_argentinian', 'is_menus_cuisine_type_hispanic', 'is_menus_cuisine_type_tapas_small_plates', 'is_menus_cuisine_type_european', 'is_menus_cuisine_type_desserts_bakeries', 'is_menus_cuisine_type_south_american', 'is_menus_cuisine_type_gastropub_food', 'is_menus_cuisine_type_other', 'is_menus_cuisine_type_guatemalan', 'is_menus_cuisine_type_brazilian', 'is_menus_cuisine_type_korean', 'is_menus_cuisine_type_colombian', 'is_menus_cuisine_type_pizza', 'is_menus_cuisine_type_indonesian', 'is_menus_cuisine_type_balkan', 'is_menus_cuisine_type_srilankan', 'is_menus_cuisine_type_indian', 'is_menus_cuisine_type_hawaiian', 'is_menus_cuisine_type_jewish', 'is_menus_cuisine_type_taiwanese', 'is_menus_cuisine_type_african', 'is_menus_cuisine_type_middle_eastern', 'is_menus_cuisine_type_vegan', 'is_menus_cuisine_type_asian_noodle_soup', 'is_menus_cuisine_type_french', 'is_menus_cuisine_type_german', 'is_menus_cuisine_type_russian', 'is_menus_cuisine_type_vietnamese', 'is_menus_cuisine_type_brunch', 'is_menus_cuisine_type_australian', 'is_menus_cuisine_type_cuban', 'is_menus_cuisine_type_filipino', 'is_menus_cuisine_type_vegetarian', 'is_menus_cuisine_type_turkish', 'is_menus_cuisine_type_malaysian', 'is_menus_cuisine_type_british', 'is_menus_cuisine_type_salvadorian', 'is_menus_cuisine_type_north_african', 'is_menus_cuisine_type_greek', 'is_menus_cuisine_type_burmese', 'is_menus_cuisine_type_east_european', 'is_menus_cuisine_type_nordic', 'is_menus_cuisine_type_north_american', 'is_menus_cuisine_type_american', 'is_menus_cuisine_type_italian', 'is_menus_cuisine_type_seafood', 'is_menus_cuisine_type_soul_food', 'is_menus_cuisine_type_californian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "menus['course_count'] = menus['Count of distinct Menu Dish Id']\n",
    "menus = menus[['Id', 'Cook Id', 'is_menus_cuisine_type_portuguese', 'is_menus_cuisine_type_irish', 'is_menus_cuisine_type_cajun_creole', 'is_menus_cuisine_type_polynesian', 'is_menus_cuisine_type_chinese', 'is_menus_cuisine_type_peruvian', 'is_menus_cuisine_type_chamorro', 'is_menus_cuisine_type_belgian', 'is_menus_cuisine_type_central_american', 'is_menus_cuisine_type_mediterranean', 'is_menus_cuisine_type_japanese', 'is_menus_cuisine_type_mexican', 'is_menus_cuisine_type_singaporean', 'is_menus_cuisine_type_ecuadorian', 'is_menus_cuisine_type_persian', 'is_menus_cuisine_type_lao', 'is_menus_cuisine_type_asian', 'is_menus_cuisine_type_latin_american', 'is_menus_cuisine_type_spanish', 'is_menus_cuisine_type_ice_cream_gelato', 'is_menus_cuisine_type_barbecue', 'is_menus_cuisine_type_cafe', 'is_menus_cuisine_type_thai', 'is_menus_cuisine_type_paleo', 'is_menus_cuisine_type_caribbean', 'is_menus_cuisine_type_health_food', 'is_menus_cuisine_type_argentinian', 'is_menus_cuisine_type_hispanic', 'is_menus_cuisine_type_tapas_small_plates', 'is_menus_cuisine_type_european', 'is_menus_cuisine_type_desserts_bakeries', 'is_menus_cuisine_type_south_american', 'is_menus_cuisine_type_gastropub_food', 'is_menus_cuisine_type_other', 'is_menus_cuisine_type_guatemalan', 'is_menus_cuisine_type_brazilian', 'is_menus_cuisine_type_korean', 'is_menus_cuisine_type_colombian', 'is_menus_cuisine_type_pizza', 'is_menus_cuisine_type_indonesian', 'is_menus_cuisine_type_balkan', 'is_menus_cuisine_type_srilankan', 'is_menus_cuisine_type_indian', 'is_menus_cuisine_type_hawaiian', 'is_menus_cuisine_type_jewish', 'is_menus_cuisine_type_taiwanese', 'is_menus_cuisine_type_african', 'is_menus_cuisine_type_middle_eastern', 'is_menus_cuisine_type_vegan', 'is_menus_cuisine_type_asian_noodle_soup', 'is_menus_cuisine_type_french', 'is_menus_cuisine_type_german', 'is_menus_cuisine_type_russian', 'is_menus_cuisine_type_vietnamese', 'is_menus_cuisine_type_brunch', 'is_menus_cuisine_type_australian', 'is_menus_cuisine_type_cuban', 'is_menus_cuisine_type_filipino', 'is_menus_cuisine_type_vegetarian', 'is_menus_cuisine_type_turkish', 'is_menus_cuisine_type_malaysian', 'is_menus_cuisine_type_british', 'is_menus_cuisine_type_salvadorian', 'is_menus_cuisine_type_north_african', 'is_menus_cuisine_type_greek', 'is_menus_cuisine_type_burmese', 'is_menus_cuisine_type_east_european', 'is_menus_cuisine_type_nordic', 'is_menus_cuisine_type_north_american', 'is_menus_cuisine_type_american', 'is_menus_cuisine_type_italian', 'is_menus_cuisine_type_seafood', 'is_menus_cuisine_type_soul_food', 'is_menus_cuisine_type_californian', 'course_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_meals = meals.merge(menus, how='inner', left_on='Menu Id', right_on='Id', suffixes=['_meal', '_menu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooks = pd.read_csv('./cleaned/cooks.csv', header=None, names=['Id', 'Cuisine Types', 'Day of Date Joined', 'Cooking Experience', 'Cooking Experience Years', 'Date of Application', 'Reasons For Cooking', 'Referrer', 'is_cooks_cuisine_type_portuguese', 'is_cooks_cuisine_type_cajun_creole', 'is_cooks_cuisine_type_chinese', 'is_cooks_cuisine_type_peruvian', 'is_cooks_cuisine_type_chamorro', 'is_cooks_cuisine_type_central_american', 'is_cooks_cuisine_type_mediterranean', 'is_cooks_cuisine_type_japanese', 'is_cooks_cuisine_type_mexican', 'is_cooks_cuisine_type_ecuadorian', 'is_cooks_cuisine_type_pizza', 'is_cooks_cuisine_type_persian', 'is_cooks_cuisine_type_asian', 'is_cooks_cuisine_type_latin_american', 'is_cooks_cuisine_type_spanish', 'is_cooks_cuisine_type_ice_cream_gelato', 'is_cooks_cuisine_type_barbecue', 'is_cooks_cuisine_type_brunch', 'is_cooks_cuisine_type_paleo', 'is_cooks_cuisine_type_caribbean', 'is_cooks_cuisine_type_argentinian', 'is_cooks_cuisine_type_vietnamese', 'is_cooks_cuisine_type_tapas_small_plates', 'is_cooks_cuisine_type_burmese', 'is_cooks_cuisine_type_desserts_bakeries', 'is_cooks_cuisine_type_south_american', 'is_cooks_cuisine_type_gastropub_food', 'is_cooks_cuisine_type_other', 'is_cooks_cuisine_type_brazilian', 'is_cooks_cuisine_type_korean', 'is_cooks_cuisine_type_colombian', 'is_cooks_cuisine_type_european', 'is_cooks_cuisine_type_indonesian', 'is_cooks_cuisine_type_lao', 'is_cooks_cuisine_type_indian', 'is_cooks_cuisine_type_hawaiian', 'is_cooks_cuisine_type_jewish', 'is_cooks_cuisine_type_taiwanese', 'is_cooks_cuisine_type_african', 'is_cooks_cuisine_type_middle_eastern', 'is_cooks_cuisine_type_french', 'is_cooks_cuisine_type_asian_noodle_soup', 'is_cooks_cuisine_type_greek', 'is_cooks_cuisine_type_vegan', 'is_cooks_cuisine_type_german', 'is_cooks_cuisine_type_russian', 'is_cooks_cuisine_type_thai', 'is_cooks_cuisine_type_australian', 'is_cooks_cuisine_type_balkan', 'is_cooks_cuisine_type_filipino', 'is_cooks_cuisine_type_vegetarian', 'is_cooks_cuisine_type_turkish', 'is_cooks_cuisine_type_malaysian', 'is_cooks_cuisine_type_british', 'is_cooks_cuisine_type_health_food', 'is_cooks_cuisine_type_north_african', 'is_cooks_cuisine_type_hispanic', 'is_cooks_cuisine_type_american', 'is_cooks_cuisine_type_east_european', 'is_cooks_cuisine_type_nordic', 'is_cooks_cuisine_type_north_american', 'is_cooks_cuisine_type_californian', 'is_cooks_cuisine_type_seafood', 'is_cooks_cuisine_type_soul_food', 'is_cooks_cuisine_type_italian', 'is_reason_meet', 'is_reason_brand', 'is_reason_money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooks['Cooking Experience Years'].fillna('missing', inplace=True)\n",
    "cooks['Cooking Experience'].fillna('missing', inplace=True)\n",
    "cooks['Referrer'].fillna('missing', inplace=True)\n",
    "cooks['cook_applied_date'] = pd.to_datetime(cooks['Date of Application'])\n",
    "cooks['cook_joined_date'] = pd.to_datetime(cooks['Day of Date Joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_and_add_to_set(column_values, unique_structure, split_character):\n",
    "    for val in column_values.split(split_character):\n",
    "        unique_structure.add(val)\n",
    "\n",
    "def clean_value(val):\n",
    "    return val.replace('/', '_').replace(' ', '_').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_cooking_experience_years_values = set()\n",
    "\n",
    "cooks['Cooking Experience Years'].apply(split_and_add_to_set, args=(unique_cooking_experience_years_values, ',', ))\n",
    "\n",
    "for category in unique_cooking_experience_years_values:\n",
    "    if len(category) > 0:\n",
    "        column_name = 'is_cooking_experience_years_' + clean_value(category)\n",
    "        cooks[column_name] = cooks['Cooking Experience Years'].apply(lambda x: 1 if category in x.split(',') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_cooking_experience_values = set()\n",
    "\n",
    "cooks['Cooking Experience'].apply(split_and_add_to_set, args=(unique_cooking_experience_values, ' or ', ))\n",
    "\n",
    "for category in unique_cooking_experience_values:\n",
    "    if len(category) > 0:\n",
    "        column_name = 'is_cooking_experience_' + clean_value(category)\n",
    "        cooks[column_name] = cooks['Cooking Experience'].apply(lambda x: 1 if category in x.split(',') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_referrer_values = set()\n",
    "\n",
    "cooks['Referrer'].apply(split_and_add_to_set, args=(unique_referrer_values, ',', ))\n",
    "\n",
    "for category in unique_referrer_values:\n",
    "    if len(category) > 0:\n",
    "        column_name = 'is_cook_referrer_' + clean_value(category)\n",
    "        cooks[column_name] = cooks['Referrer'].apply(lambda x: 1 if category in x.split(',') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooks['cooks_missing_applied_date'] = cooks['cook_applied_date'].isnull().apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooks['is_cooks_join_reason_meet'] = cooks['is_reason_meet']\n",
    "cooks['is_cooks_join_reason_brand'] = cooks['is_reason_brand']\n",
    "cooks['is_cooks_join_reason_money'] = cooks['is_reason_money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooks = cooks[['Id', 'cook_joined_date', 'cook_applied_date', 'cooks_missing_applied_date', 'is_cooking_experience_years_8+', 'is_cooking_experience_years_1-3', 'is_cooking_experience_years_4-7', 'is_cooking_experience_years_0', 'is_cooking_experience_years_missing', 'is_cooking_experience_current-chef', 'is_cooking_experience_avid', 'is_cooking_experience_former-chef', 'is_cooking_experience_missing', 'is_cooking_experience_home_cook', 'is_cooking_experience_ownerf', 'is_cooking_experience_novice', 'is_cooking_experience_private', 'is_cooking_experience_entrepreneur', 'is_cooking_experience_caterer', 'is_cooking_experience_chef_de_partie', 'is_cooking_experience_personal_chef', 'is_cooking_experience_chef_de_cuisine', 'is_cooking_experience_chef-in-traning', 'is_cooking_experience_commis', 'is_cooking_experience_sous_chef', 'is_cook_referrer_google', 'is_cook_referrer_missing', 'is_cook_referrer_job', 'is_cook_referrer_other', 'is_cook_referrer_social', 'is_cook_referrer_news', 'is_cook_referrer_referral', 'is_cook_referrer_meal', 'is_cook_referrer_friend', 'is_cooks_join_reason_meet', 'is_cooks_join_reason_brand', 'is_cooks_join_reason_money']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_meals = expanded_meals.merge(cooks, how='inner', left_on='Cook Id', right_on='Id', suffixes=['_meal2', '_cook'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "venues = pd.read_csv('./cleaned/venues.csv', header=None, names=['Id', 'Name', 'Venue Style', 'Location Id', 'Area Id', 'Max Seats', 'Monthly Services', 'Owner Id', 'Address', 'Day of Date Added', 'Neighborhood', 'Zipcode'])\n",
    "venues['Name'].fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unqiue_venue_style = set()\n",
    "\n",
    "venues['Venue Style'].apply(split_and_add_to_set, args=(unqiue_venue_style, ',', ))\n",
    "\n",
    "for category in unqiue_venue_style:\n",
    "    if len(category) > 0:\n",
    "        column_name = 'is_venue_style_' + clean_value(category)\n",
    "        venues[column_name] = venues['Venue Style'].apply(lambda x: 1 if category in x.split(',') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_venues = ['TheGarage', 'theNewberry', 'theLab', 'theUnion', 'theBocca', 'theTradesman', 'Foundation Cafe', 'Private Location', 'sound and savor', 'theCommons', 'The Humboldt House', 'theGreenhouse', 'Olea', 'R.T.B. At Dabba', 'Golden State Room', 'Tournant', 'Picnic on Third', 'Frances', 'theClub', 'Home', 'My Home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for venue in popular_venues:\n",
    "    venues['is_venue_name_' + venue] = venues['Name'].apply(lambda x: 1 if x.strip() == venue else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "venues = venues[['Id','is_venue_style_pop-up-space', 'is_venue_style_apartment', 'is_venue_style_restaurant','is_venue_style_farm', 'is_venue_style_house', 'is_venue_style_brown-stone', 'is_venue_name_TheGarage', 'is_venue_name_theNewberry', 'is_venue_name_theLab', 'is_venue_name_theUnion', 'is_venue_name_theBocca', 'is_venue_name_theTradesman', 'is_venue_name_Foundation Cafe', 'is_venue_name_Private Location', 'is_venue_name_sound and savor', 'is_venue_name_theCommons', 'is_venue_name_The Humboldt House', 'is_venue_name_theGreenhouse', 'is_venue_name_Olea', 'is_venue_name_R.T.B. At Dabba', 'is_venue_name_Golden State Room', 'is_venue_name_Tournant', 'is_venue_name_Picnic on Third', 'is_venue_name_Frances', 'is_venue_name_theClub', 'is_venue_name_Home', 'is_venue_name_My Home']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_meals = expanded_meals.merge(venues, how='inner', left_on='Venue Id', right_on='Id', suffixes=['_meal3', '_venue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_meals = expanded_meals[['Id_meal', 'cook_joined_date', 'meal_date', 'meal_is_on_weekday', 'listed_days', 'is_menus_cuisine_type_portuguese', 'is_menus_cuisine_type_irish', 'is_menus_cuisine_type_cajun_creole', 'is_menus_cuisine_type_polynesian', 'is_menus_cuisine_type_chinese', 'is_menus_cuisine_type_peruvian', 'is_menus_cuisine_type_chamorro', 'is_menus_cuisine_type_belgian', 'is_menus_cuisine_type_central_american', 'is_menus_cuisine_type_mediterranean', 'is_menus_cuisine_type_japanese', 'is_menus_cuisine_type_mexican', 'is_menus_cuisine_type_singaporean', 'is_menus_cuisine_type_ecuadorian', 'is_menus_cuisine_type_persian', 'is_menus_cuisine_type_lao', 'is_menus_cuisine_type_asian', 'is_menus_cuisine_type_latin_american', 'is_menus_cuisine_type_spanish', 'is_menus_cuisine_type_ice_cream_gelato', 'is_menus_cuisine_type_barbecue', 'is_menus_cuisine_type_cafe', 'is_menus_cuisine_type_thai', 'is_menus_cuisine_type_paleo', 'is_menus_cuisine_type_caribbean', 'is_menus_cuisine_type_health_food', 'is_menus_cuisine_type_argentinian', 'is_menus_cuisine_type_hispanic', 'is_menus_cuisine_type_tapas_small_plates', 'is_menus_cuisine_type_european', 'is_menus_cuisine_type_desserts_bakeries', 'is_menus_cuisine_type_south_american', 'is_menus_cuisine_type_gastropub_food', 'is_menus_cuisine_type_other', 'is_menus_cuisine_type_guatemalan', 'is_menus_cuisine_type_brazilian', 'is_menus_cuisine_type_korean', 'is_menus_cuisine_type_colombian', 'is_menus_cuisine_type_pizza', 'is_menus_cuisine_type_indonesian', 'is_menus_cuisine_type_balkan', 'is_menus_cuisine_type_srilankan', 'is_menus_cuisine_type_indian', 'is_menus_cuisine_type_hawaiian', 'is_menus_cuisine_type_jewish', 'is_menus_cuisine_type_taiwanese', 'is_menus_cuisine_type_african', 'is_menus_cuisine_type_middle_eastern', 'is_menus_cuisine_type_vegan', 'is_menus_cuisine_type_asian_noodle_soup', 'is_menus_cuisine_type_french', 'is_menus_cuisine_type_german', 'is_menus_cuisine_type_russian', 'is_menus_cuisine_type_vietnamese', 'is_menus_cuisine_type_brunch', 'is_menus_cuisine_type_australian', 'is_menus_cuisine_type_cuban', 'is_menus_cuisine_type_filipino', 'is_menus_cuisine_type_vegetarian', 'is_menus_cuisine_type_turkish', 'is_menus_cuisine_type_malaysian', 'is_menus_cuisine_type_british', 'is_menus_cuisine_type_salvadorian', 'is_menus_cuisine_type_north_african', 'is_menus_cuisine_type_greek', 'is_menus_cuisine_type_burmese', 'is_menus_cuisine_type_east_european', 'is_menus_cuisine_type_nordic', 'is_menus_cuisine_type_north_american', 'is_menus_cuisine_type_american', 'is_menus_cuisine_type_italian', 'is_menus_cuisine_type_seafood', 'is_menus_cuisine_type_soul_food', 'is_menus_cuisine_type_californian', 'course_count', 'cook_applied_date', 'cooks_missing_applied_date', 'is_cooking_experience_years_8+', 'is_cooking_experience_years_1-3', 'is_cooking_experience_years_4-7', 'is_cooking_experience_years_0', 'is_cooking_experience_years_missing', 'is_cooking_experience_current-chef', 'is_cooking_experience_avid', 'is_cooking_experience_former-chef', 'is_cooking_experience_missing', 'is_cooking_experience_home_cook', 'is_cooking_experience_ownerf', 'is_cooking_experience_novice', 'is_cooking_experience_private', 'is_cooking_experience_entrepreneur', 'is_cooking_experience_caterer', 'is_cooking_experience_chef_de_partie', 'is_cooking_experience_personal_chef', 'is_cooking_experience_chef_de_cuisine', 'is_cooking_experience_chef-in-traning', 'is_cooking_experience_commis', 'is_cooking_experience_sous_chef', 'is_cook_referrer_google', 'is_cook_referrer_missing', 'is_cook_referrer_job', 'is_cook_referrer_other', 'is_cook_referrer_social', 'is_cook_referrer_news', 'is_cook_referrer_referral', 'is_cook_referrer_meal', 'is_cook_referrer_friend', 'is_cooks_join_reason_meet', 'is_cooks_join_reason_brand', 'is_cooks_join_reason_money', 'is_venue_style_pop-up-space', 'is_venue_style_apartment', 'is_venue_style_restaurant', 'is_venue_style_farm', 'is_venue_style_house', 'is_venue_style_brown-stone', 'is_venue_name_TheGarage', 'is_venue_name_theNewberry', 'is_venue_name_theLab', 'is_venue_name_theUnion', 'is_venue_name_theBocca', 'is_venue_name_theTradesman', 'is_venue_name_Foundation Cafe', 'is_venue_name_Private Location', 'is_venue_name_sound and savor', 'is_venue_name_theCommons', 'is_venue_name_The Humboldt House', 'is_venue_name_theGreenhouse', 'is_venue_name_Olea', 'is_venue_name_R.T.B. At Dabba', 'is_venue_name_Golden State Room', 'is_venue_name_Tournant', 'is_venue_name_Picnic on Third', 'is_venue_name_Frances', 'is_venue_name_theClub', 'is_venue_name_Home', 'is_venue_name_My Home']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days on platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cook_days_on_platform(row):\n",
    "    if (row['meal_date'] - row['cook_joined_date']).days < 0:\n",
    "        return None\n",
    "    else:\n",
    "        return (row['meal_date'] - row['cook_joined_date']).days\n",
    "\n",
    "expanded_meals['cook_days_on_platform'] = expanded_meals.apply(compute_cook_days_on_platform, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_meals['couldnt_compute_cook_days_on_platform'] = expanded_meals['cook_days_on_platform'].apply(lambda x: 0 if x > 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_meals['cook_days_on_platform'].fillna(int(expanded_meals['cook_days_on_platform'].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.merge(expanded_meals, how='inner', left_on='meal_id', right_on='Id_meal')\n",
    "del X['Id_meal']\n",
    "del X['meal_id']\n",
    "del X['meal_date']\n",
    "del X['cook_applied_date']\n",
    "del X['cook_joined_date']\n",
    "X['meal_is_on_weekday'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_portuguese'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_irish'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_cajun_creole'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_polynesian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_chinese'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_peruvian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_chamorro'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_belgian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_central_american'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_mediterranean'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_japanese'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_mexican'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_singaporean'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_ecuadorian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_persian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_lao'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_asian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_latin_american'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_spanish'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_ice_cream_gelato'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_barbecue'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_cafe'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_thai'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_paleo'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_caribbean'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_health_food'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_argentinian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_hispanic'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_tapas_small_plates'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_european'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_desserts_bakeries'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_south_american'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_gastropub_food'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_other'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_guatemalan'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_brazilian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_korean'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_colombian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_pizza'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_indonesian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_balkan'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_srilankan'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_indian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_hawaiian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_jewish'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_taiwanese'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_african'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_middle_eastern'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_vegan'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_asian_noodle_soup'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_french'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_german'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_russian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_vietnamese'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_brunch'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_australian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_cuban'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_filipino'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_vegetarian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_turkish'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_malaysian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_british'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_salvadorian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_north_african'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_greek'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_burmese'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_east_european'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_nordic'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_north_american'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_american'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_italian'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_seafood'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_soul_food'].fillna(0, inplace=True)\n",
    "X['is_menus_cuisine_type_californian'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_years_8+'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_years_1-3'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_years_4-7'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_years_0'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_years_missing'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_current-chef'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_avid'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_former-chef'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_missing'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_home_cook'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_ownerf'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_novice'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_private'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_entrepreneur'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_caterer'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_chef_de_partie'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_personal_chef'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_chef_de_cuisine'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_chef-in-traning'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_commis'].fillna(0, inplace=True)\n",
    "X['is_cooking_experience_sous_chef'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_google'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_missing'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_job'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_other'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_social'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_news'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_referral'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_meal'].fillna(0, inplace=True)\n",
    "X['is_cook_referrer_friend'].fillna(0, inplace=True)\n",
    "X['is_cooks_join_reason_meet'].fillna(0, inplace=True)\n",
    "X['is_cooks_join_reason_brand'].fillna(0, inplace=True)\n",
    "X['is_cooks_join_reason_money'].fillna(0, inplace=True)\n",
    "X['is_venue_style_pop-up-space'].fillna(0, inplace=True)\n",
    "X['is_venue_style_apartment'].fillna(0, inplace=True)\n",
    "X['is_venue_style_restaurant'].fillna(0, inplace=True)\n",
    "X['is_venue_style_farm'].fillna(0, inplace=True)\n",
    "X['is_venue_style_house'].fillna(0, inplace=True)\n",
    "X['is_venue_style_brown-stone'].fillna(0, inplace=True)\n",
    "X['is_venue_name_TheGarage'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theNewberry'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theLab'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theUnion'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theBocca'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theTradesman'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Foundation Cafe'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Private Location'].fillna(0, inplace=True)\n",
    "X['is_venue_name_sound and savor'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theCommons'].fillna(0, inplace=True)\n",
    "X['is_venue_name_The Humboldt House'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theGreenhouse'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Olea'].fillna(0, inplace=True)\n",
    "X['is_venue_name_R.T.B. At Dabba'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Golden State Room'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Tournant'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Picnic on Third'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Frances'].fillna(0, inplace=True)\n",
    "X['is_venue_name_theClub'].fillna(0, inplace=True)\n",
    "X['is_venue_name_Home'].fillna(0, inplace=True)\n",
    "X['is_venue_name_My Home'].fillna(0, inplace=True)\n",
    "X['course_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X.sold\n",
    "# del X.sold\n",
    "del X['sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = train_test_split(X.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentage_seats_sold_train = X_train[:, 0]\n",
    "percentage_seats_sold_validate = X_validate[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, [0], axis=1)\n",
    "X_validate = np.delete(X_validate, [0], axis=1)\n",
    "del X['percentage_of_seats_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4372.3783389110331"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(percentage_seats_sold_validate - model.predict_proba(X_validate)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pmf(dist, x):\n",
    "    plt.scatter(x, dist.pmf(x))\n",
    "    plt.vlines(x, 0, dist.pmf(x))\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('number of seats')\n",
    "    plt.ylabel('P(number of seats)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probability_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5374d60339bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbinom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplot_pmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probability_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_validate):\n",
    "    n, p = (x[0], probability_predictions[index][1])\n",
    "    binom = scs.distributions.binom(n,p)\n",
    "    x = np.arange(1, n, 1)\n",
    "    plot_pmf(binom, x)\n",
    "    if index == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm a bit confused as to how to interpret my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With this logistic regression, we can't ever expect it to get everything right because we're sending it mixed signals. It is almost guaranteed that rows in the feature matrix with the exact same column values will have different target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re how to set an initial price suggestion, maybe I'm figuring out how to say \"similar meals were priced between blah and blah\" and then finding the optimal price in that range?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe I should limit the scope of the problem to be first time chefs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or maybe I should scope the problem to be chefs cooking a menu for the first time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Ideas:\n",
    "- avg chef review leading up to meal (leakage warning)\n",
    "- days between chef signup and meal \n",
    "- meal sequence number (leakage warning)\n",
    "- meal menu sequence number (leakage warning)\n",
    "- something with the description column on a menu \n",
    "    - something with tfidf/count vectorizer and nmf to get latent features\n",
    "- min price for chef (leakage warning)\n",
    "- max price for chef (leakage warning)\n",
    "- avg price for chef (leakage warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100, max_depth = 30)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance...how far is my predicted probability from the percentage of seats sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs(percentage_seats_sold_validate - clf.predict_proba(X_validate)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_features = reversed(sorted([(index, x) for index, x in enumerate(clf.feature_importances_)], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in sorted_features:\n",
    "    importance = feature[1]\n",
    "    print X.columns[feature[0]], importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distance metric between the true fraction of seats sold and the predicted probability of selling a seat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is my baseline? Baseline could be total tickets sold / total number of seats. Calculate that mean - actual for each and sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate model to predict the price that chef would want as start value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = clf.predict_proba(X_validate)[:, 1].reshape(clf.predict_proba(X_validate)[:, 1].shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actuals = percentage_seats_sold_validate.reshape(percentage_seats_sold_validate.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.concatenate((predicted_probabilities, actuals), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### days on platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if probability of selling decreases as price increases (sadly, it doesn't)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for price in range(1, 100):\n",
    "    something = np.array(X_validate[6])\n",
    "    something[1] = price\n",
    "    print price, clf.predict_proba(np.array([something]))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.corpus import words\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = list(set(stop_words.ENGLISH_STOP_WORDS))\n",
    "stop_words.append(\"(', u')\")\n",
    "stop_words.append(\"-\")\n",
    "stop_words.append(\":\")\n",
    "stop_words.append(\".\")\n",
    "stop_words.append(\"!\")\n",
    "stop_words.append(\"\\u2019\")\n",
    "stop_words.append(\"\\u2022\")\n",
    "stop_words.append(\"'s\")\n",
    "stop_words.append(\"--\")\n",
    "stop_words.append(\",\")\n",
    "stop_words.append(\"ll\")\n",
    "stop_words.append(\">\")\n",
    "stop_words.append(\"<\")\n",
    "stop_words.append(\"'\")\n",
    "stop_words.append(\"(\")\n",
    "stop_words.append(\")\")\n",
    "stop_words.append(\"...\")\n",
    "stop_words.append(\"ll\")\n",
    "stop_words.append(\"s\")\n",
    "stop_words.append(\"est\")\n",
    "stop_words.append(\"''\")\n",
    "stop_words.append(\"dolor\")\n",
    "stop_words.append(\"ut\")\n",
    "stop_words.append(\"11\")\n",
    "stop_words.append(\"?\")\n",
    "stop_words.append(\"baia\")\n",
    "stop_words.append(\"al\")\n",
    "stop_words.append(\"dri\")\n",
    "stop_words.append(\"'ll\")\n",
    "stop_words.append(\"203\")\n",
    "stop_words.append(\"&\")\n",
    "stop_words.append(\"tu\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, stop_words=stop_words)\n",
    "\n",
    "vect = vectorizer.fit_transform(X)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_sklearn_nmf(term_doc_matrix, feature_names):\n",
    "    nmf = NMF(3)\n",
    "    W = nmf.fit_transform(term_doc_matrix)\n",
    "    print ('components: {}'.format(nmf.components_))\n",
    "    print(nmf.components_.shape)\n",
    "    indices = np.argsort(nmf.components_, axis=1)[:, -20:]\n",
    "    for row in indices:\n",
    "        print ([feature_names[i] for i in row])\n",
    "    return W\n",
    "\n",
    "latent_features = implement_sklearn_nmf(vect, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets.groupby(['meal_id', 'ticket_price']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "something = pd.read_csv('./meal_seats.csv', delimiter='|', names=['meal_id', 'meal_created_date', 'meal_date', 'ticket_price',  'seats_available', 'seats_sold',  'percentage_seats_sold'])\n",
    "something['meal_year'] = pd.to_datetime(something.meal_date).apply(lambda x: x.year)\n",
    "something = something[(something.ticket_price < 200) & (something.ticket_price > 5) & (something.meal_year == 2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [8032, 7490, 7266, 6886, 6884, 6450, 6448, 6270, 6268, 6266, 6112, 6087, 5193, 4751, 4463, 4187, 4185, 4183, 4016, 3991, 8033, 7487, 7267, 7198, 6885, 6451, 6449, 6271, 6269, 6267, 6110, 6086, 5194, 4752, 4462, 4186, 4182, 4180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
